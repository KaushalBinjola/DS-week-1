{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Basics of Linear Regression and why we're doing it\n",
    "\n",
    "In this tutorial, we'll discuss one of the foundational algorithms in machine learning: *Linear regression*. We'll create a model that predicts crop yields for apples and oranges (*target variables*) by looking at the average temperature, rainfall, and humidity (*input variables or features*) in a region. Here's the training data:\n",
    "\n",
    "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
    "\n",
    "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "\n",
    "```\n",
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "```\n",
    "\n",
    "Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
    "\n",
    "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)\n",
    "\n",
    "The *learning* part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` using the training data, to make accurate predictions for new data. The _learned_ weights will be used to predict the yields for apples and oranges in a new region using the average temperature, rainfall, and humidity for that region. \n",
    "\n",
    "We'll _train_ our model by adjusting the weights slightly many times to make better predictions, using an optimization technique called *gradient descent*. Let's begin by importing Numpy and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "in this what we do is that we will make 2 arrays of independent (aka inputs) and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity) from above table.\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges) from above table\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to pytorch tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 69.,  96.,  70.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs,targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our weight kind of look like a 2X3 matrix  and our constants b1 and b2 look like vectors(arrays) <br>\n",
    "We have no idea where to start so let us assign them with random vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8489, 0.6545, 0.4170],\n",
       "         [0.0779, 0.9282, 0.1102]], requires_grad=True),\n",
       " tensor([0.4345, 0.4415], requires_grad=True))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand(2,3,requires_grad=True)\n",
    "b = torch.rand(2,requires_grad=True)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.randn` creates a tensor with the given shape, with elements picked randomly from a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) with mean 0 and standard deviation 1.\n",
    "\n",
    "Our *model* is simply a function that performs a matrix multiplication of the `inputs` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
    "\n",
    "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n",
    "\n",
    "We can define the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "# what we return from the function will be the predicted values of the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[124.1837,  73.0576],\n",
       "         [161.9645,  96.2668],\n",
       "         [186.1733, 137.9933],\n",
       "         [130.5915,  52.3771],\n",
       "         [151.0271, 102.6406]], grad_fn=<AddBackward0>),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "# compare preds with actual target\n",
    "preds, targets\n",
    "# it wont match because our preds are using random weights and constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Loss\n",
    "We use it to test how well our model actually is. Done by using MSE (mean squared error) formula usually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    diff = t1-t2\n",
    "    return torch.sum(diff*diff)/diff.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3037.6011, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8489, 0.6545, 0.4170],\n",
       "         [0.0779, 0.9282, 0.1102]], requires_grad=True),\n",
       " tensor([[6515.8926, 5994.8887, 3877.8923],\n",
       "         [ 133.3140,  -90.3685,  -91.6077]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4345, 0.4415], requires_grad=True), tensor([74.5880,  0.4671]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust weights and biases under gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using gradient descent\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[124.1837,  73.0576],\n",
       "        [161.9645,  96.2668],\n",
       "        [186.1733, 137.9933],\n",
       "        [130.5915,  52.3771],\n",
       "        [151.0271, 102.6406]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3037.6011, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[13031.7852, 11989.7773,  7755.7847],\n",
       "         [  266.6281,  -180.7370,  -183.2153]]),\n",
       " tensor([149.1760,   0.9342]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "loss.backward()\n",
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "with torch.no_grad():\n",
    "    w -= w.grad*1e-5\n",
    "    b -= b.grad*1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7186, 0.5346, 0.3394],\n",
       "         [0.0752, 0.9301, 0.1120]], requires_grad=True),\n",
       " tensor([0.4330, 0.4415], requires_grad=True))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1501.1707, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking loss again\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there has been a significant decrease in our loss value, by slight adjustments only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for multiple Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an epoch is an iteration of training the model after doing a small change on it, we will train the model using 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for 100 epochs \n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds,targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad*1e-5\n",
    "        b -= b.grad*1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(145.4011, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check loss again\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are quite close to out actual results. As we can see. We can train the model to be better by letting it run through more epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6595, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after more epochs we have\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 57.2562,  70.4212],\n",
       "         [ 81.9959, 100.3047],\n",
       "         [119.0279, 133.6108],\n",
       "         [ 21.1696,  37.1921],\n",
       "         [101.5859, 118.4862]], grad_fn=<AddBackward0>),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.],\n",
       "         [103., 119.]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using PyTorch built in functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was basic matrix operations and it is so same everywhere that pyTorch has built in functions to make and train models for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# This is pytorch for building neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37],\n",
    "                   [69, 96, 70],\n",
    "                   [74, 66, 43],\n",
    "                   [91, 87, 65],\n",
    "                   [88, 134, 59],\n",
    "                   [101, 44, 37],\n",
    "                   [68, 96, 71],\n",
    "                   [73, 66, 44],\n",
    "                   [92, 87, 64],\n",
    "                   [87, 135, 57],\n",
    "                   [103, 43, 36],\n",
    "                   [68, 97, 70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70],\n",
    "                    [81, 101],\n",
    "                    [119, 133],\n",
    "                    [22, 37],\n",
    "                    [103, 119],\n",
    "                    [57, 69],\n",
    "                    [80, 102],\n",
    "                    [118, 132],\n",
    "                    [21, 38],\n",
    "                    [104, 118],\n",
    "                    [57, 69],\n",
    "                    [82, 100],\n",
    "                    [118, 134],\n",
    "                    [20, 38],\n",
    "                    [102, 120]], dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorDataset, it allows access to rows from inputs and targets as tuples, and provides standard APIs for working with many different types of datasets in PyTorch. <br>\n",
    "TensorDataset allows us to access a small section of the training data using the array indexing notation ([0:3] in the above code). It returns a tuple with two elements. The first element contains the input variables for the selected rows, and the second contains the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs,targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader, it can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used to define weights and biases manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4944,  0.0873, -0.2832],\n",
      "        [ 0.5323, -0.5287, -0.2924]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4476, 0.5324], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,2) # it needs 2 arguments the num of inputs and num of outputs. \n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.2068,  -8.6064],\n",
       "        [ 34.9909, -16.2683],\n",
       "        [ 38.7263, -40.9651],\n",
       "        [ 44.1495,  21.2748],\n",
       "        [ 23.1129, -33.9636],\n",
       "        [ 30.6139,  -7.5454],\n",
       "        [ 34.6204, -16.0320],\n",
       "        [ 38.9375, -40.7252],\n",
       "        [ 43.7424,  20.2138],\n",
       "        [ 22.3353, -34.7883],\n",
       "        [ 29.8363,  -8.3701],\n",
       "        [ 35.3981, -15.2073],\n",
       "        [ 39.0968, -41.2015],\n",
       "        [ 44.9271,  22.0995],\n",
       "        [ 22.7058, -35.0246]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8990.0195, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "The only change is that we'll work batches of data instead of processing the entire training data in every iteration. Let's define a utility function `fit` that trains the model for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1687.1840\n",
      "Epoch [20/100], Loss: 650.8481\n",
      "Epoch [30/100], Loss: 723.2008\n",
      "Epoch [40/100], Loss: 137.0951\n",
      "Epoch [50/100], Loss: 233.8211\n",
      "Epoch [60/100], Loss: 235.2502\n",
      "Epoch [70/100], Loss: 235.9969\n",
      "Epoch [80/100], Loss: 152.6842\n",
      "Epoch [90/100], Loss: 107.7626\n",
      "Epoch [100/100], Loss: 89.6423\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.9351,  72.6955],\n",
       "        [ 79.0166,  97.9575],\n",
       "        [122.0980, 134.9642],\n",
       "        [ 31.2932,  50.1938],\n",
       "        [ 90.5719, 106.8570],\n",
       "        [ 57.8481,  71.8458],\n",
       "        [ 78.2131,  97.4590],\n",
       "        [122.0916, 135.3167],\n",
       "        [ 32.3801,  51.0435],\n",
       "        [ 90.8552, 107.2082],\n",
       "        [ 58.1315,  72.1970],\n",
       "        [ 77.9297,  97.1078],\n",
       "        [122.9016, 135.4627],\n",
       "        [ 31.0098,  49.8426],\n",
       "        [ 91.6588, 107.7067]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
